{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haodong/opt/anaconda3/envs/cs294/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle \n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "# Train, valid, and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get preprocessed train, valid, test data from the Amazon beauty dataset. In this implementation, we care only about 5 core leave one out case. Refer to https://amazon-reviews-2023.github.io/data_processing/5core.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"5core_last_out_w_his_All_Beauty\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Ratings matrix from train and valid dataset\n",
    "\n",
    "In this project, we are not going to \"train\" on anything. So we'll just use train and valid dataset to construct all ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for i in range(len(dataset['train'])):\n",
    "    ratings.append({\n",
    "        'user_id': dataset['train'][i]['user_id'],\n",
    "        'parent_asin': dataset['train'][i]['parent_asin'],\n",
    "        'rating': float(dataset['train'][i]['rating'])\n",
    "    })\n",
    "\n",
    "for j in range(len(dataset['valid'])):\n",
    "    ratings.append({\n",
    "        'user_id': dataset['valid'][j]['user_id'],\n",
    "        'parent_asin': dataset['valid'][j]['parent_asin'],\n",
    "        'rating': float(dataset['valid'][j]['rating'])\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.DataFrame(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert user and product IDs to integer indices for the matrix\n",
    "user_mapping = {user: idx for idx, user in enumerate(ratings_df['user_id'].unique())}\n",
    "product_mapping = {product: idx for idx, product in enumerate(ratings_df['parent_asin'].unique())}\n",
    "reverse_user_mapping = {idx: user for user, idx in user_mapping.items()}\n",
    "reverse_product_mapping = {idx: product for product, idx in product_mapping.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to scipy sparse matrix\n",
    "ratings_df['user_id'] = ratings_df['user_id'].map(user_mapping)\n",
    "ratings_df['parent_asin'] = ratings_df['parent_asin'].map(product_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sparse matrix\n",
    "user_item = coo_matrix(\n",
    "    (ratings_df['rating'], (ratings_df['user_id'], ratings_df['parent_asin']))\n",
    ").tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haodong/opt/anaconda3/envs/cs294/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 50/50 [00:00<00:00, 1434.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the ALS model\n",
    "model = AlternatingLeastSquares(factors=20, regularization=0.1, iterations=50)\n",
    "\n",
    "# Train the model\n",
    "model.fit(user_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = np.arange(user_item.shape[0])\n",
    "item_ids, scores = model.recommend(user_ids, user_item[user_ids], N=30)\n",
    "\n",
    "def map_value(x):\n",
    "    return reverse_product_mapping.get(x)  \n",
    "\n",
    "vectorized_map = np.vectorize(map_value)\n",
    "recommended_products = vectorized_map(item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [x['parent_asin'] for x in dataset['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(recommendations, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate Hit Rate and Recall for the recommendations.\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    recall_sum = 0\n",
    "    total_relevant_items = 0\n",
    "\n",
    "    for i, actual_items in enumerate(ground_truth):\n",
    "        recommended_items = recommendations[i]\n",
    "        actual_set = set([actual_items])\n",
    "\n",
    "        # Calculate hits (whether there's any overlap)\n",
    "        if any(item in actual_set for item in recommended_items):\n",
    "            hits += 1\n",
    "\n",
    "        # Calculate recall (proportion of relevant items in recommendations)\n",
    "        relevant_items = actual_set.intersection(recommended_items)\n",
    "        recall_sum += len(relevant_items)\n",
    "        total_relevant_items += len(actual_set)\n",
    "\n",
    "    # Hit Rate: Proportion of users with at least one hit\n",
    "    hit_rate = hits / len(ground_truth)\n",
    "\n",
    "    # Recall: Average recall across all users\n",
    "    recall = recall_sum / total_relevant_items\n",
    "\n",
    "    return {'hit_rate': hit_rate, 'recall': recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit rate is 0.1067193675889328\n",
      "recall is 0.1067193675889328\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_recommendations(recommended_products, ground_truth)\n",
    "print('hit rate is', results['hit_rate'])\n",
    "print('recall is', results['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = {}\n",
    "for user, idx in user_mapping.items():\n",
    "    retrieval[user] = list(recommended_products[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../draft_retrieval/cf_retrieval.pkl', 'wb') as f:\n",
    "    pickle.dump(retrieval, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs294",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
